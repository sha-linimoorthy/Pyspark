{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zmad3fpTcVc",
        "outputId": "24236e4e-9580-4c26-b79b-f9e4e6c25769"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cTImCIFUcMT",
        "outputId": "e871e93d-567a-4893-efde-f24919cfc84a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=cdc523935349ca98e3d82ac8c84398d44968207470c9efc4c87f29cfe02a4525\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzCDMtIiTDbp",
        "outputId": "3e5dc41a-4a30-426c-93f1-b283ecda0f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: shacodes\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/tylerx/flights-and-airports-data\n",
            "Downloading flights-and-airports-data.zip to ./flights-and-airports-data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27.1M/27.1M [00:00<00:00, 62.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "url = \"https://www.kaggle.com/datasets/tylerx/flights-and-airports-data\"\n",
        "od.download(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
      ],
      "metadata": {
        "id": "VoLpEUrLXFUo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "h6MWi1a7f2p7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/flights-and-airports-data/flights.csv\"\n",
        "spark_df=spark.read.csv(data_path,inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "v7GM2tyRdXoH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFnnrbr1dz8K",
        "outputId": "5f258ee4-4082-4ec6-bde0-6c4d2fb967bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------+---------------+-------------+--------+--------+\n",
            "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
            "+----------+---------+-------+---------------+-------------+--------+--------+\n",
            "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
            "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
            "+----------+---------+-------+---------------+-------------+--------+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark_df.select(\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", ((col(\"ArrDelay\") > 45).cast(\"Int\").alias(\"label\")))\n",
        "data.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNOD5zKAd8Zv",
        "outputId": "e9c770bf-4c9f-4ec1-e155-590910c57857"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------+---------------+-------------+--------+-----+\n",
            "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|label|\n",
            "+----------+---------+-------+---------------+-------------+--------+-----+\n",
            "|        19|        5|     DL|          11433|        13303|      -3|    0|\n",
            "|        19|        5|     DL|          14869|        12478|       0|    0|\n",
            "|        19|        5|     DL|          14057|        14869|      -4|    0|\n",
            "|        19|        5|     DL|          15016|        11433|      28|    0|\n",
            "|        19|        5|     DL|          11193|        12892|      -6|    0|\n",
            "|        19|        5|     DL|          10397|        15016|      -1|    0|\n",
            "|        19|        5|     DL|          15016|        10397|       0|    0|\n",
            "|        19|        5|     DL|          10397|        14869|      15|    0|\n",
            "|        19|        5|     DL|          10397|        10423|      33|    0|\n",
            "|        19|        5|     DL|          11278|        10397|     323|    1|\n",
            "+----------+---------+-------+---------------+-------------+--------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits = data.randomSplit([0.7, 0.3])\n",
        "train = splits[0]\n",
        "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
        "train_data = train.count()\n",
        "test_data = test.count()\n",
        "print(\"Training Rows:\", train_data, \" Testing Rows:\", test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Im3xuBreMX5",
        "outputId": "873d9e09-e74d-48dc-84b0-40126afcaecd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Rows: 1892385  Testing Rows: 809833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "carrierIndexer = StringIndexer(inputCol=\"Carrier\", outputCol=\"CarrierIndex\")\n",
        "featureAssembler = VectorAssembler(inputCols=[\"CarrierIndex\", \"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\"],\n",
        "                                   outputCol=\"catFeatures\")\n",
        "featureIndexer = VectorIndexer(inputCol=featureAssembler.getOutputCol(), outputCol=\"indexedCatFeatures\")\n",
        "numericAssembler = VectorAssembler(inputCols=[\"DepDelay\"], outputCol=\"numFeatures\")\n",
        "minMaxScaler = MinMaxScaler(inputCol=numericAssembler.getOutputCol(), outputCol=\"scaledNumFeatures\")\n",
        "finalAssembler = VectorAssembler(inputCols=[\"indexedCatFeatures\", \"scaledNumFeatures\"], outputCol=\"features\")\n",
        "\n",
        "logisticRegression = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.3)\n",
        "\n",
        "pipeline = Pipeline(stages=[carrierIndexer, featureAssembler, featureIndexer, numericAssembler, minMaxScaler, finalAssembler, logisticRegression])\n"
      ],
      "metadata": {
        "id": "C3dz8IZde2kE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "piplineModel = pipeline.fit(train)"
      ],
      "metadata": {
        "id": "gwQ1d3wZlpBh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = piplineModel.transform(test)\n",
        "predicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
        "predicted.show(50, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfEovt7jlsCO",
        "outputId": "3af64019-6ae5-4a75-a35a-270e841dbeed"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+----------+---------+\n",
            "|features                                           |prediction|trueLabel|\n",
            "+---------------------------------------------------+----------+---------+\n",
            "|[10.0,1.0,0.0,10397.0,12264.0,0.03115264797507788] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10397.0,13851.0,0.03167185877466251] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10397.0,13851.0,0.03374870197300104] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,11433.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,11433.0,0.03115264797507788] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,13244.0,0.029595015576323987]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,13487.0,0.027518172377985463]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,13487.0,0.030633437175493248]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,14869.0,0.027518172377985463]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10423.0,14869.0,0.029595015576323987]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10529.0,11193.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10529.0,11193.0,0.030633437175493248]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10529.0,11433.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10529.0,14492.0,0.0430944963655244]  |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10693.0,10397.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10693.0,12478.0,0.12357217030114226] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,10721.0,11193.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10721.0,12478.0,0.03115264797507788] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10721.0,12478.0,0.05192107995846314] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10721.0,13931.0,0.028556593977154723]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10792.0,11433.0,0.03686396677050883] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10792.0,12478.0,0.03271028037383177] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10821.0,11193.0,0.07840083073727934] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,10821.0,12478.0,0.029595015576323987]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10821.0,12478.0,0.03271028037383177] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10821.0,13487.0,0.029075804776739357]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,10821.0,13487.0,0.06749740394600208] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10821.0,14492.0,0.03167185877466251] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,10821.0,14492.0,0.07061266874350987] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,11042.0,11433.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11042.0,13487.0,0.02596053997923157] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11042.0,13487.0,0.028037383177570093]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11057.0,12478.0,0.04880581516095535] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,11057.0,13244.0,0.03115264797507788] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11066.0,10721.0,0.03946002076843198] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11066.0,13487.0,0.030114226375908618]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11066.0,13487.0,0.030633437175493248]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11066.0,13487.0,0.03115264797507788] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11066.0,13487.0,0.032191069574247146]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,10721.0,0.03115264797507788] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,10821.0,0.03426791277258567] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,10821.0,0.06490134994807892] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,11193.0,11057.0,0.027518172377985463]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,11057.0,0.028556593977154723]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,11057.0,0.06334371754932502] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,11193.0,11278.0,0.03115264797507788] |0.0       |1        |\n",
            "|[10.0,1.0,0.0,11193.0,11278.0,0.03582554517133956] |0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,11298.0,0.061266874350986496]|0.0       |1        |\n",
            "|[10.0,1.0,0.0,11193.0,11433.0,0.029595015576323987]|0.0       |0        |\n",
            "|[10.0,1.0,0.0,11193.0,11433.0,0.030114226375908618]|0.0       |0        |\n",
            "+---------------------------------------------------+----------+---------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "truePositive = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
        "falsePositive = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
        "trueNegative = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
        "falseNegative = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
        "precision = truePositive / (truePositive + falsePositive)\n",
        "recall = truePositive / (truePositive + falseNegative)\n",
        "metrics = spark.createDataFrame([\n",
        " (\"TP\", truePositive),\n",
        " (\"FP\", falsePositive),\n",
        " (\"TN\", trueNegative),\n",
        " (\"FN\", falseNegative),\n",
        " (\"Precision\", precision),\n",
        " (\"Recall\", recall),\n",
        "(\"F1\", 2*precision*recall/(recall+precision))],[\"metric\", \"value\"])\n",
        "metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycWm1vyEo0Rr",
        "outputId": "de9dad39-48af-404d-afba-9b03bf1ee550"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+\n",
            "|   metric|              value|\n",
            "+---------+-------------------+\n",
            "|       TP|             4718.0|\n",
            "|       FP|               32.0|\n",
            "|       TN|           741302.0|\n",
            "|       FN|            63781.0|\n",
            "|Precision| 0.9932631578947368|\n",
            "|   Recall|0.06887691791121038|\n",
            "|       F1|0.12882087127469316|\n",
            "+---------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "aur = evaluator.evaluate(prediction)\n",
        "print (\"AUR = \", aur)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ILFR3WCl3Mf",
        "outputId": "ebbcb98f-075b-4d53-ae66-7f832c0fa5d7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUR =  0.9750475415879148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(logisticRegression.regParam, [0.7, 0.1, 0.5]) \\\n",
        "    .addGrid(logisticRegression.maxIter, [10, 5, 15]) \\\n",
        "    .addGrid(logisticRegression.threshold, [0.4, 0.5, 0.6]) \\\n",
        "    .build()\n",
        "\n",
        "cv = CrossValidator(estimator=pipeline,\n",
        "                    evaluator=BinaryClassificationEvaluator(),\n",
        "                    estimatorParamMaps=paramGrid,\n",
        "                    numFolds=2)\n",
        "\n",
        "model = cv.fit(train)\n"
      ],
      "metadata": {
        "id": "WoKpCKxAovsO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newPrediction = model.transform(test)\n",
        "newPredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
        "newPredicted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r83CxsnAvhuO",
        "outputId": "10e8f06c-5fb7-4864-ab71-c009c9d60ff3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+---------+\n",
            "|            features|prediction|trueLabel|\n",
            "+--------------------+----------+---------+\n",
            "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,106...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,106...|       0.0|        1|\n",
            "|[10.0,1.0,0.0,107...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,107...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,107...|       0.0|        0|\n",
            "|[10.0,1.0,0.0,107...|       0.0|        0|\n",
            "+--------------------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "truePositive2 = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
        "falsePositive2 = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
        "trueNegative2 = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
        "falseNegative2 = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
        "precision2 = truePositive2 / (truePositive2 + falsePositive2)\n",
        "recall2 = truePositive2 / (truePositive2 + falseNegative2)\n",
        "metrics = spark.createDataFrame([\n",
        " (\"TP\", truePositive),\n",
        " (\"FP\", falsePositive),\n",
        " (\"TN\", trueNegative),\n",
        " (\"FN\", falseNegative),\n",
        " (\"Precision\", precision),\n",
        " (\"Recall\", recall),\n",
        "(\"F1\", 2*precision2*recall2/(recall2+precision2))],[\"metric\", \"value\"])\n",
        "metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zNbl-KyvmhT",
        "outputId": "a47c5171-13ec-4ec6-f1df-3a15c8e7636e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+\n",
            "|   metric|              value|\n",
            "+---------+-------------------+\n",
            "|       TP|             4718.0|\n",
            "|       FP|               32.0|\n",
            "|       TN|           741302.0|\n",
            "|       FN|            63781.0|\n",
            "|Precision| 0.9932631578947368|\n",
            "|   Recall|0.06887691791121038|\n",
            "|       F1|0.12882087127469316|\n",
            "+---------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "aur = evaluator.evaluate(newPrediction)\n",
        "print (\"AUR = \", aur)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAwnYvxWvy_Z",
        "outputId": "fcd95277-4707-42c5-e075-6a43a3e8ec8c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUR =  0.9750696069075243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCX7j7XQNLcj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}